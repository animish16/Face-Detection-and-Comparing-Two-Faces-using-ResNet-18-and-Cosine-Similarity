{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hw2p2_recitation_ResNet18.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zk-dSARKpIgw"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/animish16/Face-Detection-and-Comparing-Two-Faces-using-ResNet-18-and-Cosine-Similarity/blob/main/hw2p2_recitation_ResNet18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhE5p5L_fCxR"
      },
      "source": [
        "# Initializations\n",
        "___\n",
        "\n",
        "* Custom Dataset & DataLoader\n",
        "* Torchvision ImageFolder Dataset\n",
        "* Residual Block\n",
        "* CNN model with Residual Block\n",
        "* Loss Functions (Center Loss and Triplet Loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CjliQM5fCxY"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAxIJwA3fCxZ"
      },
      "source": [
        "# Initializations\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# import torch.optim as optim\n",
        "# cuda = torch.cuda.is_available()\n",
        "# import matplotlib.pyplot as plt\n",
        "import pytz\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3A1z-0tvBPv"
      },
      "source": [
        "## Unzipping and folder restructuring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6aDEPv3u_Nv"
      },
      "source": [
        "# # Data unzipping and re-arrangement\n",
        "# !unzip 11-785-s20-hw2p2-classification.zip\n",
        "# !rm 11-785-s20-hw2p2-classification.zip\n",
        "# !tar -zxvf 11-785-hw2p2-s20.tgz\n",
        "# !rm 11-785-hw2p2-s20.tgz\n",
        "# !mv 11-785hw2p2-s20/* ~/hw2p2\n",
        "\n",
        "# !unzip -q test_classification.zip\n",
        "# !unzip -q test_verification.zip\n",
        "# !unzip -q train_data.zip\n",
        "# !unzip -q validation_classification.zip\n",
        "# !unzip -q validation_verification.zip\n",
        "\n",
        "# !rm test_classification.zip\n",
        "# !rm test_verification.zip\n",
        "# !rm train_data.zip\n",
        "# !rm validation_classification.zip\n",
        "# !rm validation_verification.zip\n",
        "# !rm -r __MACOSX\n",
        "# !rm -r 11-785hw2p2-s20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxD_xfaP235r"
      },
      "source": [
        "## Print layer details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h24T1kh3235s"
      },
      "source": [
        "# class PrintLayer(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(PrintLayer, self).__init__()\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         print(str(x.shape))\n",
        "#         return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9iNVyi8fCyw"
      },
      "source": [
        "## Residual Block\n",
        "\n",
        "Resnet: https://arxiv.org/pdf/1512.03385.pdf\n",
        "\n",
        "Here is a basic usage of shortcut in Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orSMX1eRfCyx"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, channel_size, channel_size_out, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(channel_size, channel_size_out, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(channel_size_out)\n",
        "        self.conv2 = nn.Conv2d(channel_size_out, channel_size_out, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(channel_size_out)\n",
        "        if stride > 1:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(channel_size, channel_size_out, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(channel_size_out)\n",
        "            )\n",
        "        else:\n",
        "            self.shortcut = None\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        if self.shortcut:\n",
        "            identity = self.shortcut(identity)\n",
        "        out += identity\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uOI3BV-7_D5"
      },
      "source": [
        "## Bottleneck (Not Required)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtIiKHUf7-uK"
      },
      "source": [
        "# class Bottleneck(nn.Module):\n",
        "#     expansion = 4\n",
        "\n",
        "#     def __init__(self, channel_size, channel_size_out, stride=1):\n",
        "#         # channel_size_out = channel_size\n",
        "#         super(Bottleneck, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(channel_size, channel_size_out, kernel_size=1, bias=False)\n",
        "#         self.bn1 = nn.BatchNorm2d(channel_size_out)\n",
        "#         self.conv2 = nn.Conv2d(channel_size_out, channel_size_out, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "#         self.bn2 = nn.BatchNorm2d(channel_size_out)\n",
        "#         self.conv3 = nn.Conv2d(channel_size_out, self.expansion*channel_size_out, kernel_size=1, bias=False)\n",
        "#         self.bn3 = nn.BatchNorm2d(self.expansion*channel_size_out)\n",
        "\n",
        "#         self.shortcut = nn.Sequential()\n",
        "#         if stride != 1 or channel_size != self.expansion*channel_size_out:\n",
        "#             self.shortcut = nn.Sequential(\n",
        "#                 nn.Conv2d(channel_size, self.expansion*channel_size_out, kernel_size=1, stride=stride, bias=False),\n",
        "#                 nn.BatchNorm2d(self.expansion*channel_size_out)\n",
        "#             )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         out = F.relu(self.bn1(self.conv1(x)))\n",
        "#         out = F.relu(self.bn2(self.conv2(out)))\n",
        "#         out = self.bn3(self.conv3(out))\n",
        "#         out += self.shortcut(x)\n",
        "#         out = F.relu(out)\n",
        "#         return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IeGGp0U8haM"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM5vOaLA8i8h"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, layer = BasicBlock, num_layers = [2, 2, 2, 2], num_classes=2300):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(layer, 64, num_layers[0], stride=1)\n",
        "        self.layer2 = self._make_layer(layer, 128, num_layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(layer, 256, num_layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(layer, 512, num_layers[3], stride=2)\n",
        "        self.linear = nn.Linear(8192, num_classes)\n",
        "        \n",
        "        # For creating the embedding to be passed into the Center Loss criterion\n",
        "        self.linear_closs = nn.Linear(8192, 128, bias=False)\n",
        "        self.relu_closs = nn.ReLU(inplace=True)\n",
        "\n",
        "    def _make_layer(self, layer, planes, num_layers, stride):\n",
        "        strides = [stride] + [1]*(num_layers-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(layer(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * layer.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = F.relu(self.bn1(self.conv1(x)))\n",
        "        output = self.layer1(output)\n",
        "        output = self.layer2(output)\n",
        "        output = self.layer3(output)\n",
        "        output = self.layer4(output)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        label_output = self.linear(output)\n",
        "        \n",
        "        # Create the feature embedding for the Center Loss\n",
        "        closs_output = self.linear_closs(output)\n",
        "#         closs_output = self.relu_closs(closs_output)\n",
        "        \n",
        "        return closs_output, label_output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35fVCrepfCy8"
      },
      "source": [
        "### Training & Testing Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtKlmTcbfCy-"
      },
      "source": [
        "def train(model, data_loader, test_loader, task='Classification'):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(numEpochs):\n",
        "        print(\"Train: \", datetime.now(pytz.timezone('US/Eastern')).strftime(\"%Y-%m-%d %H:%M\"))\n",
        "        avg_loss = 0.0\n",
        "        print_batch = len(data_loader) // 20\n",
        "        batch_display = tqdm(enumerate(data_loader), total=len(data_loader), desc=\"current loss: 0\", leave=True, position=0)\n",
        "        for batch_num, (feats, labels) in batch_display:\n",
        "            feats, labels = feats.to(device), labels.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(feats)[1]\n",
        "            # outputs = outputs[1]\n",
        "\n",
        "            # loss = criterion(outputs, labels.long())\n",
        "            loss = criterion(outputs, labels.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            avg_loss += loss.item()\n",
        "\n",
        "            if batch_num % print_batch == (print_batch - 1):\n",
        "                batch_display.set_description(\"current loss: %.4f\" % (avg_loss / print_batch))\n",
        "                avg_loss = 0.0\n",
        "            \n",
        "            torch.cuda.empty_cache()\n",
        "            del feats\n",
        "            del labels\n",
        "            del loss\n",
        "        \n",
        "#         print(\"Val: \", datetime.now(pytz.timezone('US/Eastern')).strftime(\"%Y-%m-%d %H:%M\"))\n",
        "        if task == 'Classification':\n",
        "            val_loss, val_acc = test_classify(model, test_loader)\n",
        "            train_loss, train_acc = test_classify(model, data_loader)\n",
        "            print('Train Loss: {:.4f}\\tTrain Accuracy: {:.4f}\\tVal Loss: {:.4f}\\tVal Accuracy: {:.4f}'.\n",
        "                  format(train_loss, train_acc, val_loss, val_acc))\n",
        "#         else:\n",
        "#             test_verify(model, test_loader)\n",
        "            \n",
        "        torch.save(model.state_dict(), \"model_e\" + str(epoch + 1) + \"_\" + datetime.now(pytz.timezone('US/Eastern')).strftime(\"%Y%m%d%H%M\") + \".pt\")\n",
        "\n",
        "\n",
        "def test_classify(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = []\n",
        "    accuracy = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_num, (feats, labels) in enumerate(test_loader):\n",
        "        feats, labels = feats.to(device), labels.to(device)\n",
        "        outputs = model(feats)[1]\n",
        "        \n",
        "        _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)\n",
        "        pred_labels = pred_labels.view(-1)\n",
        "        \n",
        "        # loss = criterion(outputs, labels.long())\n",
        "        loss = criterion(outputs, labels.long())\n",
        "        \n",
        "        accuracy += torch.sum(torch.eq(pred_labels, labels)).item()\n",
        "        total += len(labels)\n",
        "        test_loss.extend([loss.item()]*feats.size()[0])\n",
        "        del feats\n",
        "        del labels\n",
        "\n",
        "    model.train()\n",
        "    return np.mean(test_loss), accuracy/total\n",
        "\n",
        "\n",
        "# def test_verify(model, test_loader):\n",
        "#     raise NotImplemented"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFSGzf6zfCzB"
      },
      "source": [
        "## Dataset, DataLoader and Constant Declarations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B4yGiQ72358"
      },
      "source": [
        "#### Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3gZ_PFs2358"
      },
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_normal_(m.weight.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJJBN6hW235-"
      },
      "source": [
        "#### Training transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhiA0zGa235_"
      },
      "source": [
        "transform_train = torchvision.transforms.Compose([\n",
        "#     transforms.RandomCrop(32, padding=4),\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.ToTensor()\n",
        "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ6KTlAb236B"
      },
      "source": [
        "#### Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvo3pna8fCzC"
      },
      "source": [
        "train_dataset = torchvision.datasets.ImageFolder(root='train_data/medium/', transform=transform_train)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=32)\n",
        "\n",
        "dev_dataset = torchvision.datasets.ImageFolder(root='validation_classification/medium/', transform=transform_train)\n",
        "dev_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=128, shuffle=True, num_workers=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjCNrSCK236F"
      },
      "source": [
        "#### Set hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjPFTI6xfCzH"
      },
      "source": [
        "numEpochs = 5\n",
        "num_feats = 3\n",
        "\n",
        "learningRate = 5e-2\n",
        "weightDecay = 5e-5\n",
        "\n",
        "hidden_sizes = [32, 64]\n",
        "num_classes = len(train_dataset.classes)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCwimLrCfCzO"
      },
      "source": [
        "# network = Network(num_feats, hidden_sizes, num_classes)\n",
        "# network.apply(init_weights)\n",
        "network = ResNet()\n",
        "network.apply(init_weights)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "# optimizer = torch.optim.Adam(network.parameters(), lr=learningRate, weight_decay=weightDecay)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8lr8qoD236K"
      },
      "source": [
        "#### Load a saved network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2eUspPF236L",
        "outputId": "700c4524-fd14-4dd7-8040-161b06e67ee6"
      },
      "source": [
        "# network.to(device)\n",
        "# network.load_state_dict(torch.load('model_e5_202003111707.pt'))\n",
        "# network.load_state_dict(torch.load('model_e1_202003112054.pt'))\n",
        "# network.load_state_dict(torch.load('model_e2_202003112215.pt'))\n",
        "# network.load_state_dict(torch.load('model_e1_202003112328.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtRO44VC236O"
      },
      "source": [
        "#### Count parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Khm3ASsG236O"
      },
      "source": [
        "# def count_parameters(model):\n",
        "#     total_param = 0\n",
        "#     for name, param in model.named_parameters():\n",
        "#         if param.requires_grad:\n",
        "#             num_param = np.prod(param.size())\n",
        "#             if param.dim() > 1:\n",
        "#                 print(name, ':', 'x'.join(str(x) for x in list(param.size())), '=', num_param)\n",
        "#             else:\n",
        "#                 print(name, ':', num_param)\n",
        "#             total_param += num_param\n",
        "#     return total_param\n",
        "\n",
        "# count_parameters(network)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyNL52RJ236Q"
      },
      "source": [
        "### Network training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGDIlM5DfCzV",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "13b457b9-eeef-4a3f-d54f-b54b248b895a"
      },
      "source": [
        "network.train()\n",
        "network.to(device)\n",
        "train(network, train_dataloader, dev_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  2020-03-11 03:46\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 3.8027: 100%|██████████| 6424/6424 [20:00<00:00,  5.35it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 3.7048\tTrain Accuracy: 0.2932\tVal Loss: 4.0157\tVal Accuracy: 0.2500\n",
            "Train:  2020-03-11 04:10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 2.6836: 100%|██████████| 6424/6424 [20:23<00:00,  5.25it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 2.4319\tTrain Accuracy: 0.4954\tVal Loss: 2.9258\tVal Accuracy: 0.4196\n",
            "Train:  2020-03-11 04:34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 2.1975: 100%|██████████| 6424/6424 [20:32<00:00,  5.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 1.8591\tTrain Accuracy: 0.5965\tVal Loss: 2.5647\tVal Accuracy: 0.4676\n",
            "Train:  2020-03-11 04:58\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 1.8336: 100%|██████████| 6424/6424 [29:27<00:00,  3.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 1.3872\tTrain Accuracy: 0.6887\tVal Loss: 2.3018\tVal Accuracy: 0.5274\n",
            "Train:  2020-03-11 05:35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 1.5706: 100%|██████████| 6424/6424 [21:06<00:00,  5.07it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1834\tTrain Accuracy: 0.7248\tVal Loss: 2.2482\tVal Accuracy: 0.5443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0XXKOcl236U",
        "outputId": "286fdf1b-3549-49ac-cdcb-44cfe8c08aef"
      },
      "source": [
        "numEpochs = 3\n",
        "learningRate = 5e-2\n",
        "weightDecay = 5e-5\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "train(network, train_dataloader, dev_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  2020-03-11 06:03\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 1.3798: 100%|██████████| 6424/6424 [19:57<00:00,  5.36it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 1.0247\tTrain Accuracy: 0.7541\tVal Loss: 2.3139\tVal Accuracy: 0.5367\n",
            "Train:  2020-03-11 06:26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 1.2325: 100%|██████████| 6424/6424 [20:01<00:00,  5.35it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.8020\tTrain Accuracy: 0.8025\tVal Loss: 2.2546\tVal Accuracy: 0.5539\n",
            "Train:  2020-03-11 06:50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 1.0981: 100%|██████████| 6424/6424 [20:00<00:00,  5.35it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6960\tTrain Accuracy: 0.8238\tVal Loss: 2.3177\tVal Accuracy: 0.5567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZqG1jcy236W",
        "outputId": "20bf9373-6821-4250-e0dd-fea48d0cb1e9"
      },
      "source": [
        "numEpochs = 5\n",
        "learningRate = 2e-2\n",
        "weightDecay = 1e-4\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "train(network, train_dataloader, dev_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  2020-03-11 07:14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.3733: 100%|██████████| 6424/6424 [20:09<00:00,  5.31it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1972\tTrain Accuracy: 0.9556\tVal Loss: 1.9207\tVal Accuracy: 0.6289\n",
            "Train:  2020-03-11 07:38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.2930: 100%|██████████| 6424/6424 [20:16<00:00,  5.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1631\tTrain Accuracy: 0.9637\tVal Loss: 1.9866\tVal Accuracy: 0.6276\n",
            "Train:  2020-03-11 08:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.2992: 100%|██████████| 6424/6424 [20:17<00:00,  5.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1849\tTrain Accuracy: 0.9546\tVal Loss: 2.0568\tVal Accuracy: 0.6187\n",
            "Train:  2020-03-11 08:25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.3962: 100%|██████████| 6424/6424 [20:16<00:00,  5.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2685\tTrain Accuracy: 0.9288\tVal Loss: 2.2219\tVal Accuracy: 0.5902\n",
            "Train:  2020-03-11 08:49\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.5061: 100%|██████████| 6424/6424 [20:15<00:00,  5.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3215\tTrain Accuracy: 0.9147\tVal Loss: 2.2178\tVal Accuracy: 0.5826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUFkj29S236Y",
        "outputId": "f4707f5a-5f54-46dc-cf5a-cb783280641c"
      },
      "source": [
        "numEpochs = 5\n",
        "learningRate = 1e-2\n",
        "weightDecay = 1e-4\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "train(network, train_dataloader, dev_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  2020-03-11 09:13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.1160: 100%|██████████| 6424/6424 [20:08<00:00,  5.32it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0590\tTrain Accuracy: 0.9899\tVal Loss: 1.8709\tVal Accuracy: 0.6498\n",
            "Train:  2020-03-11 09:37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0665: 100%|██████████| 6424/6424 [20:05<00:00,  5.33it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0428\tTrain Accuracy: 0.9940\tVal Loss: 1.8711\tVal Accuracy: 0.6578\n",
            "Train:  2020-03-11 10:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0483: 100%|██████████| 6424/6424 [20:04<00:00,  5.33it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0276\tTrain Accuracy: 0.9974\tVal Loss: 1.8128\tVal Accuracy: 0.6633\n",
            "Train:  2020-03-11 10:25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0388: 100%|██████████| 6424/6424 [20:06<00:00,  5.32it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0229\tTrain Accuracy: 0.9985\tVal Loss: 1.7436\tVal Accuracy: 0.6717\n",
            "Train:  2020-03-11 10:48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0328: 100%|██████████| 6424/6424 [20:07<00:00,  5.32it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0201\tTrain Accuracy: 0.9992\tVal Loss: 1.6986\tVal Accuracy: 0.6776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q_ocr__236a",
        "outputId": "f70efe06-84fc-47c2-c338-8b9b273fd4b9"
      },
      "source": [
        "numEpochs = 5\n",
        "learningRate = 5e-3\n",
        "weightDecay = 2e-4\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "train(network, train_dataloader, dev_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  2020-03-11 11:12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0238: 100%|██████████| 6424/6424 [20:10<00:00,  5.31it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0172\tTrain Accuracy: 0.9997\tVal Loss: 1.6386\tVal Accuracy: 0.6789\n",
            "Train:  2020-03-11 11:36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0277: 100%|██████████| 6424/6424 [20:12<00:00,  5.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0187\tTrain Accuracy: 0.9998\tVal Loss: 1.5750\tVal Accuracy: 0.6911\n",
            "Train:  2020-03-11 12:00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0325: 100%|██████████| 6424/6424 [20:14<00:00,  5.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0225\tTrain Accuracy: 0.9999\tVal Loss: 1.5507\tVal Accuracy: 0.6896\n",
            "Train:  2020-03-11 12:24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0384: 100%|██████████| 6424/6424 [20:15<00:00,  5.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0257\tTrain Accuracy: 0.9999\tVal Loss: 1.5390\tVal Accuracy: 0.6896\n",
            "Train:  2020-03-11 12:48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0444: 100%|██████████| 6424/6424 [19:59<00:00,  5.36it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0295\tTrain Accuracy: 0.9999\tVal Loss: 1.5353\tVal Accuracy: 0.6885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBYI_2Ea236c"
      },
      "source": [
        "#### CSV checkpoint 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGLMw7wW236c",
        "outputId": "ffd22cff-5a00-4062-b187-6a4ca7fb7339"
      },
      "source": [
        "numEpochs = 10\n",
        "learningRate = 2e-3\n",
        "weightDecay = 2e-4\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "train(network, train_dataloader, dev_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  2020-03-11 15:07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0316: 100%|██████████| 6424/6424 [20:20<00:00,  5.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0239\tTrain Accuracy: 1.0000\tVal Loss: 1.5069\tVal Accuracy: 0.6965\n",
            "Train:  2020-03-11 15:31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0315: 100%|██████████| 6424/6424 [20:14<00:00,  5.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0230\tTrain Accuracy: 1.0000\tVal Loss: 1.4969\tVal Accuracy: 0.6954\n",
            "Train:  2020-03-11 15:55\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0328: 100%|██████████| 6424/6424 [20:32<00:00,  5.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0235\tTrain Accuracy: 1.0000\tVal Loss: 1.4846\tVal Accuracy: 0.6980\n",
            "Train:  2020-03-11 16:19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0333: 100%|██████████| 6424/6424 [20:14<00:00,  5.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0252\tTrain Accuracy: 1.0000\tVal Loss: 1.4877\tVal Accuracy: 0.7002\n",
            "Train:  2020-03-11 16:43\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0339: 100%|██████████| 6424/6424 [20:24<00:00,  5.25it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0251\tTrain Accuracy: 1.0000\tVal Loss: 1.4843\tVal Accuracy: 0.6978\n",
            "Train:  2020-03-11 17:07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0:   5%|▍         | 307/6424 [00:58<19:24,  5.25it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g5yM0ay236f"
      },
      "source": [
        "#### CSV checkpoint 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohhNEkBA236f",
        "outputId": "1ddad557-4600-4523-e6c6-bfc4969fdaf9"
      },
      "source": [
        "numEpochs = 2\n",
        "learningRate = 5e-2\n",
        "weightDecay = 1e-4\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "train(network, train_dataloader, dev_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  2020-03-11 18:02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 1.9112: 100%|██████████| 6424/6424 [20:53<00:00,  5.13it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 1.6200\tTrain Accuracy: 0.6332\tVal Loss: 2.5037\tVal Accuracy: 0.4848\n",
            "Train:  2020-03-11 18:27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 1.5758: 100%|██████████| 6424/6424 [20:55<00:00,  5.12it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1111\tTrain Accuracy: 0.7359\tVal Loss: 2.2514\tVal Accuracy: 0.5437\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-IMB5_O236h",
        "outputId": "7d4e3008-68d6-4b50-a59b-a2badab37077"
      },
      "source": [
        "numEpochs = 2\n",
        "learningRate = 2e-2\n",
        "weightDecay = 1e-4\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "train(network, train_dataloader, dev_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  2020-03-11 18:51\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.6535: 100%|██████████| 6424/6424 [20:41<00:00,  5.18it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3739\tTrain Accuracy: 0.9115\tVal Loss: 1.8128\tVal Accuracy: 0.6417\n",
            "Train:  2020-03-11 19:15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.5339: 100%|██████████| 6424/6424 [20:38<00:00,  5.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2961\tTrain Accuracy: 0.9266\tVal Loss: 1.9001\tVal Accuracy: 0.6274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WjncsK3236k",
        "outputId": "b899f3ab-e97a-443c-cc71-e7871b47dcc3"
      },
      "source": [
        "numEpochs = 2\n",
        "learningRate = 1e-2\n",
        "weightDecay = 1e-4\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "train(network, train_dataloader, dev_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  2020-03-11 19:40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.1721: 100%|██████████| 6424/6424 [20:59<00:00,  5.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0860\tTrain Accuracy: 0.9836\tVal Loss: 1.7323\tVal Accuracy: 0.6722\n",
            "Train:  2020-03-11 20:04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.1049: 100%|██████████| 6424/6424 [21:00<00:00,  5.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0607\tTrain Accuracy: 0.9900\tVal Loss: 1.7402\tVal Accuracy: 0.6748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsN8Jqmi236m",
        "outputId": "5f90b690-5ada-4768-b9be-4464a4ad70fb"
      },
      "source": [
        "numEpochs = 2\n",
        "learningRate = 5e-3\n",
        "weightDecay = 5e-5\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "train(network, train_dataloader, dev_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  2020-03-11 21:27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0278: 100%|██████████| 6424/6424 [20:26<00:00,  5.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0170\tTrain Accuracy: 0.9985\tVal Loss: 1.7001\tVal Accuracy: 0.6852\n",
            "Train:  2020-03-11 21:51\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0189: 100%|██████████| 6424/6424 [20:35<00:00,  5.20it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz3MPSRn236o",
        "outputId": "87422fca-9f59-43d9-b893-4eb598d0f43b"
      },
      "source": [
        "numEpochs = 1\n",
        "learningRate = 1e-3\n",
        "weightDecay = 5e-5\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "train(network, train_dataloader, dev_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  2020-03-11 22:34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0131: 100%|██████████| 6424/6424 [48:36<00:00,  2.20it/s]     \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0099\tTrain Accuracy: 0.9996\tVal Loss: 1.7009\tVal Accuracy: 0.6900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A2KAt-L236q"
      },
      "source": [
        "#### CSV checkpoint 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVORoPCV236q",
        "outputId": "9da4d501-9685-4a83-f5d7-2ec8a194eb30"
      },
      "source": [
        "numEpochs = 5\n",
        "learningRate = 1e-3\n",
        "weightDecay = 1e-5\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "train(network, train_dataloader, dev_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  2020-03-11 23:38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "current loss: 0.0112: 100%|██████████| 6424/6424 [20:13<00:00,  5.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0091\tTrain Accuracy: 0.9997\tVal Loss: 1.6838\tVal Accuracy: 0.6933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AiWMG37236s"
      },
      "source": [
        "#### CSV checkpoint 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc7RkjbO236s"
      },
      "source": [
        "numEpochs = 5\n",
        "learningRate = 1e-3\n",
        "weightDecay = 1e-5\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "train(network, train_dataloader, dev_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-WLANH_236u"
      },
      "source": [
        "#### CSV checkpoint 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvhYjFa4hMf9"
      },
      "source": [
        "## Test predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcgLaTvRzdPA"
      },
      "source": [
        "idx_to_class = {}\n",
        "for key in train_dataset.class_to_idx.keys():\n",
        "    idx_to_class[train_dataset.class_to_idx[key]] = key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw8C87NM4fkF"
      },
      "source": [
        "class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n",
        "    def __getitem__(self, index):\n",
        "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
        "        path = self.imgs[index][0]\n",
        "        tuple_with_path = (original_tuple + (path,))\n",
        "        return tuple_with_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwS6CMwmRpQj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98477244-2112-4434-b508-7917333a5ce8"
      },
      "source": [
        "test_dataset = ImageFolderWithPaths(root='test_classification/', transform=torchvision.transforms.ToTensor())\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False, num_workers=8)\n",
        "\n",
        "def test_predictions(model, test_loader):\n",
        "    model.eval()\n",
        "    test_predictions = {}\n",
        "\n",
        "    for batch_num, (feats, labels, filename) in enumerate(test_loader):\n",
        "        feats, labels = feats.to(device), labels.to(device)\n",
        "        outputs = model(feats)[1]\n",
        "        \n",
        "        _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)\n",
        "        pred_labels = pred_labels.view(-1)\n",
        "        for i in range(len(pred_labels)):\n",
        "            test_predictions[filename[i]] = pred_labels[i].cpu().tolist()\n",
        "\n",
        "    return test_predictions\n",
        "\n",
        "test_predicted_raw_labels = test_predictions(network, test_dataloader)\n",
        "len(test_predicted_raw_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4600"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkgtB9B64xpP"
      },
      "source": [
        "blist = [[batch_num, first] for batch_num, first in enumerate(test_dataset)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebQOZMsbwxul"
      },
      "source": [
        "test_predicted_labels = {}\n",
        "for key in test_predicted_raw_labels.keys():\n",
        "    test_predicted_labels[key.replace('test_classification/medium/', '')] = idx_to_class[test_predicted_raw_labels[key]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JojgOBhOwYiA"
      },
      "source": [
        "with open(\"classification_\" + datetime.now(pytz.timezone('US/Eastern')).strftime(\"%Y%m%d%H%M\") + \".csv\", 'w') as f:\n",
        "    f.write('Id,Category\\n')\n",
        "    for key in test_predicted_labels.keys():\n",
        "        f.write(\"%s,%s\\n\"%(key,test_predicted_labels[key]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk-dSARKpIgw"
      },
      "source": [
        "## Verification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9whwZ-gqnLi"
      },
      "source": [
        "test_verification_file = open(\"test_trials_verification_student.txt\")\n",
        "\n",
        "with test_verification_file as file:\n",
        "    test_verification_file_lines = file.readlines()\n",
        "\n",
        "test_verification_first_images = []\n",
        "test_verification_second_images = []\n",
        "for line in test_verification_file_lines:\n",
        "    line_split = line.replace('\\n', '').split(' ')\n",
        "    test_verification_first_images.append(line_split[0])\n",
        "    test_verification_second_images.append(line_split[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lenOHtjTuBTV",
        "outputId": "db5a8ca8-7b77-4abf-c5de-0c6ab260582c"
      },
      "source": [
        "# !mkdir verification_images\n",
        "# !mv test_verification verification_images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘verification_images’: File exists\n",
            "mv: cannot stat 'test_verification': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfFx4N4wpKKv",
        "outputId": "7834fa47-998d-4835-c314-d73a76bfbbc3"
      },
      "source": [
        "verification_dataset = ImageFolderWithPaths(root='verification_images/', transform=torchvision.transforms.ToTensor())\n",
        "verification_dataloader = torch.utils.data.DataLoader(verification_dataset, batch_size=10, shuffle=False, num_workers=8)\n",
        "\n",
        "def test_verification_probabilities(model, test_loader):\n",
        "    model.eval()\n",
        "    test_features = {}\n",
        "    \n",
        "    for batch_num, (feats, labels, filename) in enumerate(test_loader):\n",
        "        feats, labels = feats.to(device), labels.to(device)\n",
        "        outputs = model(feats)[0]\n",
        "        \n",
        "        for i in range(len(outputs)):\n",
        "            test_features[filename[i].replace('verification_images/test_verification/', '')] = outputs[i].cpu().tolist()\n",
        "\n",
        "    return test_features\n",
        "\n",
        "test_predicted_raw_probs = test_verification_probabilities(network, verification_dataloader)\n",
        "len(test_predicted_raw_probs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "169392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ0x65bo237D",
        "outputId": "aa11f620-c1c3-470d-d6e8-9d6ce21a2a2c"
      },
      "source": [
        "files_list = []\n",
        "similarity_list = []\n",
        "\n",
        "for i in range(len(test_verification_first_images)):\n",
        "    f = test_verification_first_images[i]\n",
        "    s = test_verification_second_images[i]\n",
        "    files_list.append(f + \" \" + s)\n",
        "    similarity_list.append(\n",
        "        np.dot(test_predicted_raw_probs[f], test_predicted_raw_probs[s]) / (np.linalg.norm(test_predicted_raw_probs[f]) * np.linalg.norm(test_predicted_raw_probs[s]))\n",
        "    )\n",
        "files_list[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'262615.jpg 207587.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjfpFzi8fCzu"
      },
      "source": [
        "with open(\"verification_\" + datetime.now(pytz.timezone('US/Eastern')).strftime(\"%Y%m%d%H%M\") + \".csv\", 'w') as f:\n",
        "    f.write('trial,score\\n')\n",
        "    for i in range(len(files_list)):\n",
        "        f.write(\"%s,%s\\n\"%(files_list[i], similarity_list[i]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
